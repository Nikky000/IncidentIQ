# IncidentIQ - AI Incident Resolution Assistant

> **Zero vendor lock-in. Production-ready. DevOps-first.**

**ğŸ‰ NEW: v2.0 with 4-Stage Hybrid Retrieval Pipeline - 40-50% better accuracy!**

> **[See v2.0 Documentation](./README_V2.md)** | **[GTMT Strategy](./docs/GTM_STRATEGY.md)** | **[Implementation Summary](./IMPLEMENTATION_SUMMARY.md)**

IncidentIQ is an AI-powered incident resolution assistant that learns from your war room channels and helps teams resolve production incidents faster by finding similar past incidents with precision-tiered matching.

---

## ğŸ¯ Key Features

- **ğŸ¯ Precision-Tiered Matching** - EXACT (â‰¥92%), PARTIAL (70-92%), or NONE (<70%)
- **ğŸ”Œ Zero Vendor Lock-In** - Use any LLM/embedding provider via LiteLLM
- **ğŸ’° 40-70% Cost Reduction** - Semantic caching for LLM responses
- **ğŸ¤– Slack Bot** - Learn from war room channels automatically
- **âš¡ Production-Ready** - Circuit breakers, rate limiting, health checks
- **ğŸ—„ï¸ DB-Backed Config** - Change settings without redeployment

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- API keys for LLM/embedding providers (or use Ollama locally)

### Installation

```bash
# Clone repository
cd incidentiq

# Install dependencies
make install

# Copy environment file
cp .env.example .env

# Edit .env with your settings
nano .env
```

### Running Locally (Development)

```bash
# Start all services with Docker
make docker-up

# Or run API only (requires Redis, Postgres, Qdrant running)
make dev
```

### Running Tests

```bash
# Run all tests
make test

# Run with coverage
pytest --cov=src --cov-report=html

# Fast tests (stop on first failure)
make test-fast
```

---

## ğŸ“ Project Structure

```
incidentiq/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/           # FastAPI REST endpoints
â”‚   â”œâ”€â”€ bots/          # Slack bot integration
â”‚   â”œâ”€â”€ core/          # Pattern matching engine, config, utils
â”‚   â”œâ”€â”€ db/            # Database models and config service
â”‚   â””â”€â”€ services/      # LLM, embedding, cache services
â”œâ”€â”€ tests/             # Comprehensive test suite
â”œâ”€â”€ scripts/           # Database initialization
â”œâ”€â”€ config/            # Nginx load balancer config
â”œâ”€â”€ Dockerfile         # Production-ready container
â”œâ”€â”€ docker-compose.yml # Full stack deployment
â””â”€â”€ Makefile           # Development commands
```

---

## ğŸ”§ Configuration

### Environment Variables

Create `.env` from `.env.example`:

```bash
# Application
APP_ENV=development

# Database (only this needed if using DB-backed config)
DATABASE_URL=postgresql+asyncpg://user:pass@localhost:5432/incidentiq

# LLM Provider (supports 100+ providers via LiteLLM)
LLM_MODEL=anthropic/claude-3-5-sonnet
ANTHROPIC_API_KEY=your_key

# Or use OpenAI
LLM_MODEL=openai/gpt-4o
OPENAI_API_KEY=your_key

# Or use local Ollama (FREE)
LLM_MODEL=ollama/llama2
LLM_API_BASE=http://localhost:11434

# Or use custom enterprise endpoint
LLM_MODEL=openai/your-model
LLM_API_BASE=https://your-company-llm.com/v1
OPENAI_API_KEY=your_enterprise_key

# Embedding
EMBEDDING_MODEL=openai/text-embedding-3-small

# Vector Database
QDRANT_URL=http://localhost:6333

# Cache
REDIS_URL=redis://localhost:6379/0
```

### Database-Backed Configuration

All settings can be stored in PostgreSQL for dynamic updates:

```python
from src.db.config_service import get_db_config_service

config = await get_db_config_service()

# Get value
threshold = await config.get("EXACT_MATCH_THRESHOLD", default=0.92)

# Set value (with audit log)
await config.set(
    key="EXACT_MATCH_THRESHOLD",
    value=0.95,
    value_type="float",
    changed_by="admin",
    reason="Increased precision requirements"
)
```

---

## ğŸ“Š API Endpoints

### Search Similar Incidents

```bash
POST /api/v1/search
```

```json
{
  "query": "database connection timeout on postgresql",
  "limit": 5,
  "filters": {
    "service": "api-gateway",
    "severity": "high"
  }
}
```

Response:

```json
{
  "total_matches": 2,
  "exact_matches": 1,
  "partial_matches": 1,
  "matches": [
    {
      "incident_id": "INC-234",
      "title": "PostgreSQL Connection Pool Exhausted",
      "similarity_score": 0.95,
      "confidence": "EXACT",
      "resolved_by": "john_doe",
      "resolution_summary": "Increased max_connections from 100 to 200",
      "match_reasons": ["Same error type", "Same service"]
    }
  ]
}
```

### Index New Incident

```bash
POST /api/v1/incidents
```

```json
{
  "id": "INC-001",
  "title": "Database Connection Timeout",
  "description": "PostgreSQL connections timing out after 30s",
  "error_message": "psycopg2.OperationalError: connection timeout",
  "service": "api-gateway",
  "severity": "high",
  "resolved_by": "john_doe",
  "resolution_summary": "Increased connection pool size"
}
```

### Health Check

```bash
GET /health
```

---

## ğŸ¤– Slack Bot Usage

### Commands

- `/incidentiq search <query>` - Search for similar incidents
- `/incidentiq help` - Show help message

### Automatic Learning

The bot automatically learns from war room channels:

1. Add bot to your war room channel: `/invite @IncidentIQ`
2. Bot listens to all incident discussions
3. Extracts patterns, resolutions, and expert knowledge
4. Indexes for future searches

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Slack Bot  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pattern Engine â”‚  â”‚  LLM Service     â”‚   â”‚
â”‚  â”‚ (THE USP)      â”‚  â”‚  (LiteLLM)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚          â”‚          â”‚              â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚Qdrant â”‚  â”‚Postgresâ”‚ â”‚  Redis  â”‚  â”‚ Circuit â”‚
â”‚Vector â”‚  â”‚  DB    â”‚ â”‚  Cache  â”‚  â”‚ Breaker â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Testing

Run the test suite:

```bash
# All tests
make test

# Specific test file
pytest tests/test_pattern_matching.py -v

# Coverage report
pytest --cov=src --cov-report=html
open htmlcov/index.html
```

Test coverage:
- Pattern matching engine: âœ…
- LLM service with caching: âœ…
- Circuit breaker & rate limiter: âœ…
- API endpoints: âœ…
- Database models: âœ…

---

## ğŸš¢ Deployment

### Using Docker Compose

```bash
# Production deployment
make prod-up

# View logs
make docker-logs

# Scale API servers
docker-compose up -d --scale api=3
```

### Environment Setup

1. Set DB password:
   ```bash
   export DB_PASSWORD=your_secure_password
   ```

2. Start services:
   ```bash
   docker-compose up -d
   ```

3. Initialize database:
   ```bash
   make db-migrate
   ```

---

## ğŸ’¡ Cost Optimization

| Feature | Savings |
|---------|---------|
| **Semantic Caching** | 40-70% LLM cost reduction |
| **Embedding Cache** | Avoid re-embedding same content |
| **Open-source Qdrant** | $0 vs $96+/mo Pinecone |
| **Batch Processing** | Fewer API calls |

**Estimated Costs:**
- Development: $0-25/month
- Production (100 users): $200-500/month

---

## ğŸ”’ Security

- âœ… Non-root Docker container
- âœ… Rate limiting (30 req/min per user)
- âœ… Circuit breakers for external services
- âœ… Secrets encrypted in database
- âœ… Nginx with security headers
- âœ… Health checks everywhere

---

## ğŸ¤ Contributing

```bash
# Install dev dependencies
make install

# Run linter
make lint

# Run tests
make test

# Format code
make format
```

---

## ğŸ“„ License

MIT License - see LICENSE file

---

## ğŸ™‹ Support

- ğŸ“§ Email: support@incidentiq.com
- ğŸ’¬ Slack: [Join our community]
- ğŸ“– Docs: [Full documentation]

---

**Built with â¤ï¸ for DevOps teams who need reliable incident resolution**
