# ============================================
# IncidentIQ Configuration
# ============================================
# This file supports ZERO VENDOR LOCK-IN
# Companies can bring their own LLM/Embedding endpoints
# ============================================

# === Application ===
APP_NAME=incidentiq
APP_ENV=development
DEBUG=true
LOG_LEVEL=INFO

# === API Server ===
API_HOST=0.0.0.0
API_PORT=8000

# ============================================
# LLM CONFIGURATION (Vendor Agnostic via LiteLLM)
# ============================================
# LiteLLM supports 100+ providers:
# - openai/gpt-4, openai/gpt-3.5-turbo
# - anthropic/claude-3-sonnet, anthropic/claude-3-haiku
# - azure/gpt-4-deployment-name
# - ollama/llama2, ollama/mistral (local)
# - custom endpoints: openai/my-model (with custom base_url)
#
# For custom enterprise endpoint:
# LLM_MODEL=openai/your-model-name
# LLM_API_BASE=https://your-company-llm.com/v1
# LLM_API_KEY=your-key
# ============================================

LLM_MODEL=anthropic/claude-3-5-sonnet-20241022
LLM_API_KEY=your-anthropic-key
# LLM_API_BASE=  # Optional: Custom endpoint URL

# Fallback model (if primary fails)
LLM_FALLBACK_MODEL=openai/gpt-4o-mini
LLM_FALLBACK_API_KEY=your-openai-key

# ============================================
# EMBEDDING CONFIGURATION (Vendor Agnostic)
# ============================================
# Supported providers via LiteLLM:
# - openai/text-embedding-3-small
# - openai/text-embedding-3-large
# - cohere/embed-english-v3.0
# - azure/embedding-deployment-name
# - ollama/nomic-embed-text (local, FREE)
# - custom endpoints
#
# For custom enterprise endpoint:
# EMBEDDING_MODEL=openai/your-embedding-model
# EMBEDDING_API_BASE=https://your-company-embeddings.com/v1
# ============================================

EMBEDDING_MODEL=openai/text-embedding-3-small
EMBEDDING_API_KEY=your-openai-key
# EMBEDDING_API_BASE=  # Optional: Custom endpoint URL
EMBEDDING_DIMENSIONS=1536

# ============================================
# VECTOR DATABASE (Qdrant)
# ============================================
# Self-hosted (FREE):
# QDRANT_URL=http://localhost:6333
#
# Qdrant Cloud (1GB FREE tier):
# QDRANT_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=your-qdrant-api-key
# ============================================

QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=incidents

# ============================================
# POSTGRESQL DATABASE
# ============================================
DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/incidentiq

# ============================================
# REDIS (Caching & Queues)
# ============================================
REDIS_URL=redis://localhost:6379/0

# === Caching Settings ===
CACHE_ENABLED=true
CACHE_TTL_SECONDS=3600
SEMANTIC_CACHE_ENABLED=true
SEMANTIC_CACHE_SIMILARITY_THRESHOLD=0.95

# ============================================
# SLACK BOT
# ============================================
SLACK_BOT_TOKEN=xoxb-your-bot-token
SLACK_APP_TOKEN=xapp-your-app-token
SLACK_SIGNING_SECRET=your-signing-secret

# ============================================
# PATTERN MATCHING (USP Configuration)
# ============================================
# Confidence thresholds for precision-tiered matching
EXACT_MATCH_THRESHOLD=0.92      # >= 92% = EXACT MATCH
PARTIAL_MATCH_THRESHOLD=0.70    # >= 70% = PARTIAL MATCH
MIN_MATCH_THRESHOLD=0.50        # < 50% = NO MATCH

# Number of similar incidents to retrieve
MAX_SIMILAR_INCIDENTS=5

# Hybrid search weights (vector + keyword)
VECTOR_SEARCH_WEIGHT=0.7
KEYWORD_SEARCH_WEIGHT=0.3
